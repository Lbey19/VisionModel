# üöÄ D√©ploiement VisionModel sur un autre PC

## Pr√©requis sur le nouveau PC

### 1. Installer Node.js
- T√©l√©charger : https://nodejs.org/
- Version recommand√©e : LTS (v20+)

### 2. Installer Ollama
- T√©l√©charger : https://ollama.ai/download
- Apr√®s installation, ex√©cuter :
```bash
ollama pull llama3.1:8b
ollama pull gemma2:2b
ollama pull nomic-embed-text
```

## M√©thode 1 : Git/GitHub (Recommand√©)

### √âtape 1 : Sur le PC actuel
```bash
# Initialiser Git
git init
git add .
git commit -m "Initial VisionModel commit"

# Cr√©er un repo GitHub et pousser
git remote add origin https://github.com/VOTRE_USERNAME/vision-model.git
git push -u origin main
```

### √âtape 2 : Sur le nouveau PC
```bash
# Cloner le projet
git clone https://github.com/VOTRE_USERNAME/vision-model.git
cd vision-model

# Installer les d√©pendances
npm install

# D√©marrer le serveur
npm start
```

## M√©thode 2 : Copie directe

### Fichiers essentiels √† copier :
```
VisionModel1/
‚îú‚îÄ‚îÄ server.js          # Serveur principal
‚îú‚îÄ‚îÄ package.json       # D√©pendances
‚îú‚îÄ‚îÄ start-server.bat   # Script de d√©marrage
‚îú‚îÄ‚îÄ public/            # Interface web
‚îú‚îÄ‚îÄ docs/              # Documents RAG
‚îú‚îÄ‚îÄ rag.js             # Module RAG
‚îî‚îÄ‚îÄ rag.index.json     # Index des documents
```

### √âtapes sur le nouveau PC :
1. Cr√©er dossier `VisionModel1`
2. Copier tous les fichiers
3. Ouvrir PowerShell dans le dossier
4. Ex√©cuter : `npm install`
5. D√©marrer : `.\start-server.bat`

## M√©thode 3 : Package complet

### Cr√©er un package zip avec script d'installation
```bash
# Sur PC actuel - cr√©er package
npm pack

# Inclure dans le zip :
# - Tous les fichiers du projet
# - Script d'installation automatique
# - Documentation de d√©ploiement
```

## Configuration post-d√©ploiement

### 1. V√©rifier Ollama
```bash
curl http://localhost:11434/api/tags
```

### 2. Tester l'application
```bash
curl http://localhost:3001/health
```

### 3. Interface web
Acc√©der √† : http://localhost:3001

## D√©pannage courant

### Probl√®me : Port 3001 occup√©
```bash
# Windows
netstat -ano | findstr :3001
taskkill /PID [PID_NUMBER] /F
```

### Probl√®me : Ollama non accessible
```bash
# V√©rifier le service Ollama
ollama serve
```

### Probl√®me : Modules manquants
```bash
# R√©installer les d√©pendances
npm install --force
```

## Variables d'environnement

Cr√©er `.env` si n√©cessaire :
```
OLLAMA_URL=http://127.0.0.1:11434
PORT=3001
MODEL=gemma2:2b
```

## S√©curit√©

- Ne pas exposer sur Internet sans authentification
- Utiliser un firewall local
- V√©rifier les ports ouverts

## Support

En cas de probl√®me :
1. V√©rifier les logs dans la console
2. Tester Ollama s√©par√©ment
3. V√©rifier la connectivit√© r√©seau local